{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ac9981",
   "metadata": {},
   "source": [
    "# Description des variables :\n",
    "\n",
    " **Pregancies** : Nombre de grossesses passées par la patiente.\n",
    "\n",
    " **Glucose** : Taux de glucose dans le sang (mg/dL)\n",
    "\n",
    " **BloodPressure** : Tension artérielle diastolique (mm Hg)\n",
    "\n",
    " **SkinThickness** : Épaisseur du pli cutané (mm)\n",
    "\n",
    " **Insulin** : Niveau d'insuline sérique (mu U/mL)\n",
    "\n",
    " **BMI**: Indice de masse corporelle  (poids (kg))(taille (m)^2)\n",
    "\n",
    " **DiabetesPedigreeFunction** : Fonction de pedigree du diabète (facteur génétique)\n",
    "\n",
    " **Age** : Âge de la patiente (années)\n",
    "\n",
    "\n",
    " **Outcome** : Résultat du test de dépistage du diabète (1 = diabétique, 0 = non diabétique)\n",
    "\n",
    "# Catégorisation des variables :\n",
    "\n",
    " *Variables démographique et familiale* : age, pregnancies \n",
    "\n",
    " *Variables biologiques* : glucose, bloodpressure, insulin -> indicateurs médicaux directs \n",
    "\n",
    " *Variables antropométriques* : bmi, skinthickness -> indicateurs liés au poids et à la composition corporelle\n",
    "\n",
    " *Variable génétique* : diabetespedigreefunction -> facteur de risque héréditaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520f317",
   "metadata": {
    "tags": [
     "bibliothèques"
    ]
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Manipulation des données :\n",
    "#######################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import display # pour afficher les dataframes dans les notebooks\n",
    "\n",
    "#######################################################\n",
    "# Visualisation des données :\n",
    "#######################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Analyse statistique \n",
    "#######################################################\n",
    "\n",
    "from scipy import stats # tests d'hypothèses, corrélation, distributions de proba\n",
    "from scipy.stats import normaltest, shapiro, anderson # tests de normalité d'une distribution\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau # tests de corrélation (pearson -> correlation linéaire - données quantitatives continues, normale\n",
    "# spearman  -> corrélation de rangs - données non-normales ou ordinales ; kendalltau -> corrélation de rangs - petits enchantillons\n",
    "import statsmodels.api as sm # modélisation statistique (régression, ANOVA, tests, séries temporelles\n",
    "# -> Sert à aller plus loin que scikit-learn en analyse statistique)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor # pour détecter la multicolinéarité entre variables explicatives\n",
    "# VIF Variance Inflation Factor ~= 1 -> pas de corrélation ; 1-5 modérée acceptable ; >10 forte corrélation\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Machine Learning \n",
    "#######################################################\n",
    "\n",
    "## Pre-processing \n",
    "\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, KFold, StratifiedKFold, cross_validate )\n",
    "# train_test_split : diviser les données en ensembles d'entraînement et de test\n",
    "# Kfol : validation croisée simple\n",
    "# stratifiedKFold : validation croisée en conservant la proportion des classes\n",
    "# cross_val_score : évaluer un modèle avec validation croisée\n",
    "# cross_validate : évaluer plusieurs métriques avec validation croisée \n",
    "# gridSearchCV : recherche exhaustive d'hyperparamètres -> teste toutes les combinaisons possibles\n",
    "# randomizedSearchCV : recherche aléatoire d'hyperparamètres -> teste un nombre fixe\n",
    "\n",
    "from sklearn.preprocessing import (StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer, LabelEncoder, OneHotEncoder)\n",
    "# StandardScaler : centrage-réduction (moyenne=0, écart-type=1) -> Reg linéaire, SVM, KNN, PCA\n",
    "# MinMaxScaler : mise à l'échelle entre 0 et 1 -> réseaux de neurones\n",
    "# RobustScaler : mise à l'échelle robuste aux outliers -> données avec outliers\n",
    "# QuantileTransformer : transformation non-linéaire pour rendre les données plus normales ou uniforme -> modèles linéaires\n",
    "# LabelEncoder : encoder les labels catégoriels en entiers -> variables cibles\n",
    "# OneHotEncoder : encoder les variables catégorielles en variables binaires -> variables explicatives\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "# SimpleImputer : imputation des valeurs manquantes avec moyenne, médiane, mode ou constante\n",
    "# KNNImputer : imputation des valeurs manquantes avec les k plus proches voisins\n",
    "from sklearn.feature_selection import (SelectKBest, f_regression, mutual_info_regression, RFE, RFECV, SelectFromModel)\n",
    "# SelectKBest : sélection des k meilleures caractéristiques selon un test statistique, score\n",
    "# f_regression : test F pour la régression linéaire - score pour selectKBest\n",
    "# mutual_info_regression : information mutuelle pour la régression - score pour selectKBest\n",
    "# RFE : élimination récursive des caractéristiques - sélection des caractéristiques en fonction de l'importance\n",
    "# RFECV : RFE avec validation croisée - sélection des caractéristiques en fonction de l'importance avec validation croisée\n",
    "# SelectFromModel : sélection des caractéristiques en fonction de l'importance d'un modèle (utiliser coef_ ou feature_importances_)\n",
    "\n",
    "\n",
    "## Models :\n",
    "\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression, HuberRegressor, RANSACRegressor, TheilSenRegressor)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor,\n",
    "                              AdaBoostRegressor,  BaggingRegressor)\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "## Metrics\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error, explained_variance_score,\n",
    "    max_error, median_absolute_error\n",
    ")\n",
    "\n",
    "\n",
    "## Advanced ML Libraries \n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "\n",
    "## Utility Functions \n",
    "import time # time() pour mesurer le temps d'exécution, sleep(s) pour pauses de s sec, perf_counter() pour chronométrage haute précision\n",
    "import gc #libération automatique de la mémoire non utilisée par Python -> libérer de la ram\n",
    "from tqdm import tqdm # barre de progression pour les boucles\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "## Set Random Seeds for Reproducibility \n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89fdb93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
